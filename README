```
$ cargo run --features color_eyre,display_ui,editor_ui --bin omclone
$ cargo run --features color_eyre,benchmark --bin omclone_benchmark
$ cargo test --features color_eyre,display_ui,editor_ui --bin omclone -- --nocapture


$ export LIBTORCH_USE_PYTORCH=1
$ cargo run --features color_eyre,nn --bin solver
```

# In progress

-   Actions for a single arm at a time (in order)
-   Simple MCTS without graph search

# Observations

-   When training on samples derived from MCTS where we start the search from
    a-few-moves-from-the-end, the network very quickly overspecializes to spam
    "Drop"
    -   This was partially just because I forgot to clear the input between
        timesteps, meaning it was completely useless, which meant the best the
        network could do is to blindly spam the most likely instruction
    -   In response I also tweaked the loss-weight for samples that come from
        human solutions (which ~only sees policy loss) vs those that come from
        MCTS (which ~only sees value loss)
-   Training both value and policy on a mix of human solutions (weight) +
    weak MCTS solutions, I attempted to weight the loss scale to significantly
    (x0.00001) shrink the impact of value loss for human solutions. This has
    caused the value head to become extremely sharp for MCTS solutions, even
    though the contribution of the value loss to the overall loss is very
    small (0.006 vs 2.0).
    -   Actually, why _is_ the value loss so low here? Is it just predicting
        "cycles left until cycle limit > some small number"? I think so...
    -   Solution: Generate solutions that have higher cycles-left but still
        succeed, and lower cycles-left but still fail

# Future work

Technical/impl work:

-   Generate solutions that have low cycles-left but still fail
    -   ...because the layout is bad
    -   ...because the layout is good but there's just not enough cycles left
-   Randomly generate some training samples that have no history
-   Evaluate and monitor
    -   proportion of successful solves (where it had to find _n_ moves,
        as a function of _n_?)
    -   how well does it solve with no history?
-   Train a timesteps-left head on existing solutions
-   sparse tensors forfeatures and training data (right now bottlenecked on disk
    read speed, ~500MB/s)
-   Parallelise MCTS, batch NN evaluations
-   Make net/eval/training board size agnostic
-   use symmetries to generate more data
-   network/code for generating layouts
-   better logging, saving intermediate layer outputs / residuals

Science-y investigation work:

-   Lean on existing solutions more, but be careful mixing them in with
    MCTS-generated solutions. They are from different domains; try having them
    train on non-overlapping outputs, to avoid the model overspecializing on
    "source"
-   weight and neuron activation visualization
    -   mean/stdev/activation-proportion per layer / per history
    -   max abs gradient
-   find/monitor dead neurons
-   keep more notes/observations for experiments, be more scientific about this
-   run same NN several times to get an idea of consistency
-   validation set in addition to training set

# idk

-   Does allowing action selection for any arm (rather than the next one in order)
    improve strength?
